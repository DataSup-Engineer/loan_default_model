{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loan Default Prediction System\n",
    "\n",
    "Predict loan repayment using XGBoost machine learning."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import xgboost as xgb\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report, roc_auc_score, roc_curve\n",
    "import pickle\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "sns.set_style('whitegrid')\n",
    "print('Libraries imported successfully!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Load Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('Loan_Default_data.csv', encoding='latin-1', encoding_errors='ignore')\n",
    "print(f'Shape: {df.shape}')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Analyze Missing Values & Target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "missing = pd.DataFrame({\n",
    "    'Column': df.columns,\n",
    "    'Missing': df.isnull().sum(),\n",
    "    'Percent': (df.isnull().sum() / len(df) * 100).round(2)\n",
    "})\n",
    "missing[missing['Missing'] > 0].sort_values('Percent', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Target Distribution:')\n",
    "print(df['repay_fail'].value_counts())\n",
    "print(df['repay_fail'].value_counts(normalize=True) * 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Handle missing values\n",
    "df_filled = df.copy()\n",
    "numeric_cols = df_filled.select_dtypes(include=[np.number]).columns\n",
    "for col in numeric_cols:\n",
    "    if df_filled[col].isnull().sum() > 0:\n",
    "        df_filled[col].fillna(df_filled[col].median(), inplace=True)\n",
    "\n",
    "categorical_cols = df_filled.select_dtypes(include=['object']).columns\n",
    "for col in categorical_cols:\n",
    "    if df_filled[col].isnull().sum() > 0:\n",
    "        mode_val = df_filled[col].mode()[0] if len(df_filled[col].mode()) > 0 else 'Unknown'\n",
    "        df_filled[col].fillna(mode_val, inplace=True)\n",
    "\n",
    "print(f'Missing values after imputation: {df_filled.isnull().sum().sum()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert percentages\n",
    "df_converted = df_filled.copy()\n",
    "if 'revol_util' in df_converted.columns and df_converted['revol_util'].dtype == 'object':\n",
    "    # Remove special characters, quotes, and percentage signs\n",
    "    df_converted['revol_util'] = df_converted['revol_util'].str.replace(r'[\\x93\\x94%]', '', regex=True)\n",
    "    df_converted['revol_util'] = pd.to_numeric(df_converted['revol_util'], errors='coerce') / 100\n",
    "    print('Percentage converted')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Engineer date features\n",
    "df_temporal = df_converted.copy()\n",
    "if 'earliest_cr_line' in df_temporal.columns and 'issue_d' in df_temporal.columns:\n",
    "    df_temporal['earliest_cr_line'] = pd.to_datetime(df_temporal['earliest_cr_line'], errors='coerce')\n",
    "    df_temporal['issue_d'] = pd.to_datetime(df_temporal['issue_d'], errors='coerce')\n",
    "    df_temporal['credit_history_months'] = (df_temporal['issue_d'] - df_temporal['earliest_cr_line']).dt.days / 30\n",
    "    df_temporal['issue_year'] = df_temporal['issue_d'].dt.year\n",
    "    df_temporal['issue_month'] = df_temporal['issue_d'].dt.month\n",
    "    df_temporal['issue_quarter'] = df_temporal['issue_d'].dt.quarter\n",
    "    for col in ['credit_history_months', 'issue_year', 'issue_month', 'issue_quarter']:\n",
    "        if df_temporal[col].isnull().sum() > 0:\n",
    "            df_temporal[col].fillna(df_temporal[col].median(), inplace=True)\n",
    "    print('Date features created')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop date columns\n",
    "df_no_dates = df_temporal.copy()\n",
    "date_cols = ['earliest_cr_line', 'issue_d', 'last_pymnt_d', 'next_pymnt_d', 'last_credit_pull_d']\n",
    "for col in date_cols:\n",
    "    if col in df_no_dates.columns:\n",
    "        df_no_dates.drop(col, axis=1, inplace=True)\n",
    "print(f'Remaining columns: {df_no_dates.shape[1]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encode categorical variables\n",
    "df_encoded = df_no_dates.copy()\n",
    "label_encoders = {}\n",
    "ordinal_features = ['emp_length', 'term']\n",
    "for col in ordinal_features:\n",
    "    if col in df_encoded.columns and df_encoded[col].dtype == 'object':\n",
    "        le = LabelEncoder()\n",
    "        df_encoded[col] = le.fit_transform(df_encoded[col].astype(str))\n",
    "        label_encoders[col] = le\n",
    "\n",
    "categorical_cols = df_encoded.select_dtypes(include=['object']).columns.tolist()\n",
    "if 'repay_fail' in categorical_cols:\n",
    "    categorical_cols.remove('repay_fail')\n",
    "nominal_features = [c for c in categorical_cols if c not in ordinal_features]\n",
    "if nominal_features:\n",
    "    df_encoded = pd.get_dummies(df_encoded, columns=nominal_features, drop_first=True)\n",
    "print(f'Encoded! Columns: {df_encoded.shape[1]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove identifiers\n",
    "df_clean = df_encoded.copy()\n",
    "drop_cols = ['id', 'member_id', 'zip_code', 'loan_status']\n",
    "for col in drop_cols:\n",
    "    if col in df_clean.columns:\n",
    "        df_clean.drop(col, axis=1, inplace=True)\n",
    "print(f'Final columns: {df_clean.shape[1]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split features and target\n",
    "y = df_clean['repay_fail']\n",
    "X = df_clean.drop('repay_fail', axis=1)\n",
    "feature_columns = X.columns.tolist()\n",
    "print(f'Features: {X.shape}, Target: {y.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train-test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
    "print(f'Train: {X_train.shape}, Test: {X_test.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save preprocessing info\n",
    "preprocessor_info = {\n",
    "    'label_encoders': label_encoders,\n",
    "    'feature_columns': feature_columns\n",
    "}\n",
    "with open('preprocessor_info.pkl', 'wb') as f:\n",
    "    pickle.dump(preprocessor_info, f)\n",
    "print('Preprocessing artifacts saved')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Train XGBoost Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = xgb.XGBClassifier(\n",
    "    objective='binary:logistic',\n",
    "    max_depth=6,\n",
    "    learning_rate=0.1,\n",
    "    n_estimators=100,\n",
    "    subsample=0.8,\n",
    "    colsample_bytree=0.8,\n",
    "    random_state=42\n",
    ")\n",
    "print('Model initialized')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "start = time.time()\n",
    "model.fit(X_train, y_train)\n",
    "print(f'Training complete in {time.time()-start:.2f}s')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('model.pkl', 'wb') as f:\n",
    "    pickle.dump(model, f)\n",
    "print('Model saved to model.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict(X_test)\n",
    "y_proba = model.predict_proba(X_test)[:, 1]\n",
    "print(f'Predictions generated for {len(y_test)} samples')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f'Accuracy: {accuracy:.4f} ({accuracy*100:.2f}%)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cm = confusion_matrix(y_test, y_pred)\n",
    "print('Confusion Matrix:')\n",
    "print(cm)\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', square=True)\n",
    "plt.title('Confusion Matrix')\n",
    "plt.ylabel('Actual')\n",
    "plt.xlabel('Predicted')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Classification Report:')\n",
    "print(classification_report(y_test, y_pred, target_names=['Repaid', 'Defaulted']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "roc_auc = roc_auc_score(y_test, y_proba)\n",
    "fpr, tpr, _ = roc_curve(y_test, y_proba)\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.plot(fpr, tpr, label=f'ROC (AUC = {roc_auc:.4f})', linewidth=2)\n",
    "plt.plot([0, 1], [0, 1], 'k--', label='Random')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('ROC Curve')\n",
    "plt.legend()\n",
    "plt.grid(alpha=0.3)\n",
    "plt.show()\n",
    "print(f'ROC-AUC Score: {roc_auc:.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "Model training and evaluation complete! Files saved:\n",
    "- `model.pkl` - Trained XGBoost model\n",
    "- `preprocessor_info.pkl` - Preprocessing artifacts"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
